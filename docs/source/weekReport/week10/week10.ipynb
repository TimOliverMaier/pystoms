{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10 \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "source": [
    "<!-- <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"color:blue;font-style:italic\">07.03.2022 - 11.03.2022</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(256, 76, 76,0.4)\",height=\"200\">\n",
    "\n",
    "<br>\n",
    "\n",
    "<H4>Abstract</H4>\n",
    "\n",
    "<br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "A possible approach to a bayesian model for LC-IMS-MS precursor features is a general linear model (GLM). In this week a GLM prototype was introduced into pystoms and a 3D visualization with python library plotly was implemented.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(256, 76, 76,0.4)\",height=\"200\">\n",
    "<br>\n",
    "<H4>Introduction</H4>\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(256, 76, 76,0.4)\",height=\"200\">\n",
    "<br>\n",
    "<H4>Methods and Material</H4>\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "```python3\n",
    "\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <div style=\"background-color:white\">\n",
    "\n",
    "<img src=\"data/modelGraphviz.svg\" >\n",
    "\n",
    "</div>\n",
    "<figcaption style=\"font-weight:bold;font-size:small\">\n",
    "Fig 1: Visualization of artificial Model spanning 10 submodels each receiving an independent dataset of normally distributed data of unknown mean. Visualization was created with python-graphviz <cite data-cite=\"graphviz\"></cite>.\n",
    "</figcaption> --> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(256, 76, 76,0.4)\",height=\"200\">\n",
    "<br>\n",
    "<H4>Results</H4>\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproteolizard.data import PyTimsDataHandle\n",
    "from pystoms.feature_loader_dda import FeatureLoaderDDA\n",
    "from pystoms.modelsGLM import ModelGLM3D\n",
    "import theano\n",
    "import pymc as pm\n",
    "import numpy as np\n",
    "import plotly.io as pio\n",
    "import arviz as az\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pio.renderers.default = \"sphinx_gallery\"\n",
    "# get raw data via proteolizard\n",
    "data_handle = PyTimsDataHandle('/home/tim/Master/MassSpecDaten/M210115_001_Slot1-1_1_850.d/')\n",
    "# precursors are listed in precursor table\n",
    "precursor_table = data_handle.get_selected_precursors()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ectract some features with random ids\n",
    "features = [200]\n",
    "\n",
    "feature_data = []\n",
    "charges = []\n",
    "\n",
    "for feature_id in features:\n",
    "    feature = FeatureLoaderDDA(data_handle,feature_id)\n",
    "    # estimate feature hull boundaries with averagine model for isotopic pattern and gaussian model for IMS\n",
    "    data_tmp = feature.load_hull_data_3d(ims_model=\"gaussian\",plot_feature=True)\n",
    "    feature_data.append(data_tmp)\n",
    "    charges.append(feature.charge)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first feature data is needed to declare the model\n",
    " \n",
    "s = feature_data[0][\"Scan\"].values\n",
    "m = feature_data[0][\"Mz\"].values\n",
    "# intensities must be floats, otherise observed data is not stored\n",
    "# in inference data due to pymc bug \n",
    "# https://github.com/pymc-devs/pymc/issues/5586\n",
    "i = feature_data[0][\"Intensity\"].values.astype(\"float\")\n",
    "z = charges[0]\n",
    "ims_mu = np.average(s,weights=i)\n",
    "ims_sigma = np.max(s)-np.min(s)\n",
    "mz_mu = np.average(m,weights=i)\n",
    "mz_sigma = 10\n",
    "alpha_lam = 1/np.max(i)\n",
    "myModel = ModelGLM3D(s.size,6,z,i,s,m,ims_mu,ims_sigma,mz_mu,mz_sigma,alpha_lam,\"\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "for z,feature in zip(charges,feature_data):\n",
    "  scans = feature[\"Scan\"].values\n",
    "  mzs = feature[\"Mz\"].values\n",
    "  intensities = feature[\"Intensity\"].values\n",
    "  with myModel as model:\n",
    "    # set data with current feature data\n",
    "    pm.set_data({\"charge\":z,\n",
    "                 \"scan\":scans,\n",
    "                 \"intensity\":intensities.astype(\"float\"),\n",
    "                 \"mz\":np.tile(mzs,(6,1)).T,\n",
    "                 \"peaks\":np.tile(np.arange(6),(scans.size,1)) # awful but mzs currently needed as column\n",
    "    })\n",
    "    # evalaution is driver method for pm.sample and plotting,\n",
    "    # if resample not true, model would not sample if it was \n",
    "    # already fitted\n",
    "    #\n",
    "    traces.append(model.evaluation(True,True,True,True,[\"posterior_pred_in\",\"posterior_pred_out\",\"prior_pred_in\",\"prior_pred_out\"],progressbar=False))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(256, 76, 76,0.4)\",height=\"200\">\n",
    "<br>\n",
    "<H4>Conclusion and Outlook</H4>\n",
    "<br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(256, 76, 76,0.4)\",height=\"200\">\n",
    "<br>\n",
    "<H4>References</H4>\n",
    "<br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "outputs": [],
   "source": [
    ".. bibliography:: references10.bib\n",
    "    :style:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(256, 76, 76,0.4)\",height=\"200\">\n",
    "<br>\n",
    "<H4>To Do</H4>\n",
    "<br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next Steps:\n",
    "\n",
    "1. Parallelized GLM model\n",
    "2. Model Evaluation for GLM in pystoms\n",
    "3. Feature Manager -> handling many features at once\n",
    "4. Test Model on GPU\n",
    "\n",
    "5. CPU and GPU breakdown for bigger models in pymc4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "interpreter": {
   "hash": "8ef36075318212a951d729eacf3af4e7fff5153712d0068dd271c1775548f24c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
